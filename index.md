---

layout: col-sidebar
title: OWASP Artificial Intelligence Security Verification Standard AISVS Docs
tags: AI, LLM, Security, AISVS
level: 2
type: documentation
pitch: OWASP AI verification standard for developers and testers

---

The AI Security Verification Standard (AISVS) focuses on providing developers, architects, and security professionals with a structured checklist to verify the security and ethical considerations of AI-driven applications. Modeled after existing OWASP standards (such as the ASVS for web applications), AISVS will define categories of requirements for areas including:

* Training Data Governance & Bias Management
* User Input Validation
* Model Lifecycle Management & Change Control
* Infrastructure, Configuration & Deployment Security
* Access Control & Identity for AI Components & Users
* Supply Chain Security for Models, Frameworks & Data
* Model Behavior, Output Control & Safety Assurance
* Memory, Embeddings & Vector Database Security
* Autonomous Orchestration & Agentic Action Security
* Adversarial Robustness & Attack Resistance
* Privacy Protection & Personal Data Management
* Monitoring, Logging & Anomaly Detection
* Human Oversight, Accountability & Governance
* Explainability, Interpretability & Transparency

### Road Map
Phase 1 – Research and Category List Creation

* Collect relevant industry standards and research papers (e.g., NIST AI standards, ISO/IEC guidelines, privacy regulations).
* Create an initial draft of categories that cover key security areas listed above
* Get community feedback and final approval for the category list
* Work on the category list is ongoing here: [https://github.com/OWASP/AISVS/blob/main/1.0/en/Categories.md](https://github.com/OWASP/AISVS/blob/main/1.0/en/Categories.md)

Phase 2 – Requirement Creation

* Create a list of requirements for each category
* Refine the standard based on community, partner, and subject matter expert input.

Phase 3 – Beta Release and Pilot Testing

* Release a “beta” version of AISVS (v.1).
* Invite early adopters to test AISVS on real-world AI applications and gather feedback on usability and coverage.

Phase 4 – Final 1.0 Release

* Incorporate feedback from pilot testing.
* Formally publish Version 1.0 of AISVS, including comprehensive documentation and a lightweight checklist.

Phase 5 – Continuous Improvement

* Maintain the AISVS as an open-source project, encouraging community contributions.
* Periodically release updated versions reflecting emerging threats, novel AI approaches, and regulatory changes.
